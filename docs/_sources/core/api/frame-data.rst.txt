Frame Data
==========

.. module:: scandit.datacapture.core
  :android-package: com.scandit.datacapture.core.data

.. enum:: Channel
  :available: ios=6.0, android=6.0

  Enumeration of possible channel types.

  .. value:: Y
    :available: ios=6.0, android=6.0

    Luminance (Y) or gray-scale channel

  .. value:: U
    :available: ios=6.0, android=6.0

  .. value:: V
    :available: ios=6.0, android=6.0

  .. value:: R
    :available: ios=6.0, android=6.0

    Red channel

  .. value:: G
    :available: ios=6.0, android=6.0

    Green channel

  .. value:: B
    :available: ios=6.0, android=6.0

    Blue channel

  .. value:: A
    :available: ios=6.0, android=6.0

    Alpha channel

  .. implnote:: In the future, we can add other channel types, such as Depth here.

.. enum:: DataType
  :available: none

  .. implnote:: This will be used in the future to add support for other data types, such as float, U16, S16 etc. For now, we only use 8 bit unsigned values to represent the values of pixels.

  .. value:: U8
    :available: none

    Unsigned byte

.. interface:: IFrameData
  @objc@ SDCFrameData <NSObject>
  :available: ios=6.0, android=6.0

  Interface for holding frame data from one or more sources (cameras). The concrete type is tied to the frame source that produces the frames.

  The frame data contains one or more image buffers, each of which may have different sizes. Each frame data is guaranteed to have at least one image buffer. Only frame sources that combine the input of multiple frame sources will have more than one image buffer. The images buffers can have different sizes.

  A frame contains the pixel data as well as layout of one particular frame. Frames are immutable and reference counted, so they can be shared by multiple consumers. The frame is returned to the pool (recycled) when all consumers release the frame.

  .. implnote::

    The reference counting can naturally be based on the CMSampleBufferRef reference counting on iOS, but needs to be manually implemented on Windows/Android. Reference counting the frames is less natural on Android/Windows due to the garbage collector, but still provides very nice properties:

    * frames can be shared by multiple consumers. They are released to the pool again once all the consumers are done processing.
    * it's essentially zero copy (or at most one copy on some platforms).
    * unlike normal garbage collection it's deterministic.

    To make reference counting a little less error-prone, the reference counting on Windows should be implemented using IDisposable (see Microsofts FrameReader).

  .. method:: void Retain()
    :available: android=6.0

    Increments the reference count of the video frame by one. Must be balanced by a matching call to :meth:`Release`.

  .. method:: void Release()
    :available: android=6.0

     Decrements the reference count of the video frame by one. When the reference count drops to zero, the frame is recycled. Must be balanced by a call to :meth:`Retain`.

  .. property::  int Orientation { get; }
    :available: android=6.0

    The orientation of the image buffer contained in this frame data.
    .. todo:: describe the orientation values

  .. property:: ImageBuffer ImageBuffer { get; }
    :available: android=6.0

    The image buffer contained in this frame data.

  .. property:: IList<ImageBuffer> ImageBuffers { get; }
    :available: ios=6.0

    The image buffers contained in this frame data.

  .. method:: bool Equals(Object? obj)
    :available: android=6.1

    Indicates whether some other object is equal to this one.

  .. method:: int HashCode()
    :available: android=6.1

    Returns a hash code value for the object.

.. class:: ImagePlane
  @objc@ SDCImagePlane : NSObject
  :available: ios=6.0, android=6.0

  An individual image plane as part of an image buffer. The image plane data may or may not be interleaved with other image planes.

  .. method:: ImagePlane(Channel channel, int subsamplingX, int subsamplingY, int rowStride, int pixelStride, ByteBuffer data)
    :available: android=6.0

    Creates a new image plane instance from channel, subsamplingX, subsamplingY, rowStride, pixelStride and data.

  .. property:: Channel Channel { get; }
    :available: ios=6.0, android=6.0

  .. property:: ByteBuffer Data { get; }
    @objc@  @property(nonatomic, nonnull, readonly) uint8_t * data;
    :available: ios=6.0, android=6.0

    The bytes used by this image plane. For interleaved image planes, parts of the bytes exposed this property may not be part of this plane and belong to other planes. For example, for an :type:`ImageBuffer` with red, green and blue planes using an interleaved layout, only every third byte belongs to the red image plane.

    The life-time of the data is tied to the life-time of the :type:`ImageBuffer`, which for image buffers belonging to frame data is bound to the life-time of the :type:`IFrameData` instance.

  .. property:: uint32 SubsamplingX  { get; }
    :available: ios=6.0, android=6.0

    The amount of subsampling (in pixels in X-direction). For image plane with the exception of U and V planes, the subsampling in both x and y will be 1 (meaning no subsampling). A subsampling of 2 indicates that two horizontally adjacent  pixels share the same pixel data.

  .. property:: uint32 SubsamplingY  { get; }
    :available: ios=6.0, android=6.0

    The amount of subsampling (in pixels in Y-direction). For image plane with the exception of U and V planes, the subsampling in both x and y will be 1 (meaning no subsampling). A subsampling of 2 indicates that two vertically adjacent pixels share the same pixel data.

  .. property:: uint32 RowStride { get; }
    :available: ios=6.0, android=6.0

    The number of bytes of a row of pixels. For example, an RGB image will typically have a row stride of 3 * width, with potential padding at the end to match mulitples of 4.

  .. property:: uint32 PixelStride { get; }
    :available: ios=6.0, android=6.0

    Number of bytes between two adjacent pixels part of the same image plane. In case of subsampling, this value is the number of bytes per pixel as if there were no subsampling. For example, for a non-interleaved U plane subsampled at 2, the element stride is 1.

.. class:: ImageBuffer
  @objc@ SDCImageBuffer : NSObject
  :available: ios=6.0, android=6.0

  An image buffer consists of one or more :type:`images planes <ImagePlane>` that describe how the memory is laid out. Instances of this class don't own the data, rather the data is owned by another class (typically a :type:`IFrameData` instance).

    .. method:: ImageBuffer(int width, int height, IArrayList<ImagePlane> planes)
      :available: android=6.0

      Create new image buffer instance from width, height and planes.

  .. property:: uint32 Width { get; }
    :available: ios=6.0, android=6.0

    Width of the image buffer in pixels (non-subsampled).

  .. property:: uint32 Height { get; }
    :available: ios=6.0, android=6.0

    Height of the image buffer in pixels (non-subsampled).

  .. property:: IList<ImagePlane> Planes { get; }
    :available: ios=6.0, android=6.0

    List of planes that this image buffer holds. The data used by these image planes may or may not be part of the same block of memory.

  .. todo:: platform specific convenience functionality to convert from native image/frame types to image buffer.

  .. implnote:: In addition to providing access to the data through a byte buffer/pointer, we should support directly submitting this data as a texture (vulkan, GLES, Metal). This requires us to setup GLES context sharing beforehand, so we can share the OpenGLES texture used in the moible layer with the OpenGLES context of the engine.

  .. implnote:: Currently the name strongly suggest that this is to be used for image data, but it doesn't have to be. Other data could be provided as part of the image buffer as well. Since our current use cases only really require image data and no other information, calling it image buffer still makes the most sense.

  .. method:: Bitmap ToBitmap()
    @objc@ -(nullable UIImage*) toUIImage
    :available: ios=6.1, android=6.1

    .. eager-ifconfig:: platform != 'ios'

      Converts the video frame to an RGB bitmap that can be visualized in the UI, or stored on disk.
      
      Depending on the underlying representation, this call may require an image conversion to a different format. As such, it's a relatively expensive operation. Make sure to only call this method when the image is required.

    .. eager-ifconfig:: platform == 'ios'

      Converts the video frame to a UIImage that can be visualized in the UI, or stored on disk.
      
      
    The returned image has the same dimensions as the video frame.

    

